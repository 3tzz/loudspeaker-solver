optimizer: adam
device: cuda
lr: 0.001
batch_size: 32
epochs: 10000
loss: mse
shuffle: true
scheduler:
  _target_: torch.optim.lr_scheduler.ReduceLROnPlateau
  mode: min
  factor: 0.5
  patience: 10
resume: false
output:
  path: output_surrogate/first_train
  repo_relative: true
